# Recurrent Neural Network Indepth Intuition And NLP Application

e hello guys I hope everybody's doing fine I hope you can hear me uh can I get a quick yes if you are able to hear me out yeah I hope everybody's able to hear me out can I get a quick yes if you able to hear me okay perfect so how are you all I hope you're doing fine I hope uh the NLP series is going on fine okay so um what all things we have discussed in the previous session yeah so what all things we have actually discussed in the previous session can somebody tell us so that we can start doing things so let me go ahead and quickly share my screen and then we will just start um in today's session uh we are actually going to discuss about RNN that is recurrent neural network uh this will be quite amazing because we're going to learn some amazing things now now we are going from machine learning to you know deep learning and here you will be able to do some amazing things right so this will be quite amazing uh when we are learning things and uh we'll make sure that whatever things we learn we understand it and we do it practically okay so in our previous sessions uh let me go ahead and write we have also learned about bag of words we have learned about TF IDF right then we learned about something called as word to we okay then we also learned about average word to W right all this we did with python practical implementation we have completed this practical implementation two architecture of word to w we have seen one is C and one is NG gr right sorry NP gr script script gr basically is this we have learned about this two architecture and now uh today we are uh basically going to learn about one amazing thing uh which is basically called as recurrent neural network now we are moving towards deep learning if you remember from the first session the graph that I have actually created right bottom to top so today we are going to learn about RNN then as we go ahead you'll be learning about lstm RNN third thing that we are going to see is something called as Gru RNN and then we will be seeing something called as bir directional lstm rnm right and then finally uh we will move towards encoders decoders okay uh we will also be seeing something called as Transformers now we are moving in the Deep learning part and the seventh thing we will start with b right initially we'll see um uh you know where we will be focusing more on um understanding things implementing with the help of python and some amazing libraries called estlow and then we'll also be seeing how we can Implement different different problem statements all together right so please do hit like if you're new to this Channel please make sure that you subscribe and yes uh I will also be taking some amazing interview questions um so let's start one good interview questions uh from now onwards any live classes first we'll focus on previous session interview questions okay and this can be super important interview questions in your exams or in your any kind of interview that you go with respect to data science right first thing is that what is the difference between Twain versus test versus validation data so this is the first interview question that I really want you all to answer uh you should be able see the main thing is that when you are answering interview right you should not be talking about many things just point to point what exactly is the train data test data and validation data why specifically we use validation data because this was asked to one of the candidates that had recently gone to the interview okay so everybody who can answer this please do make sure that you answer okay what is the difference between train test and validation data yeah so tell me this was asked in recent interview so I'm just asking you and you should be able to answer this precisely okay so tell me what is train data and what is validation data and all right train is used for training the model okay what about test then what about test what about test test for prediction so what about validation then test to avoid data leakage validate how much model is accurate to given data okay if if I probably take this up right uh whenever you have any kind of features right uh okay sorry whenever you have a specific data set okay initially whenever we take any kind of data set we do two types of split okay one is train training and one is test right when I say train I'm basically going to use this data for model training okay I'm basically going to use this data for model training this is exactly for model testing okay this is considered that I'm not going to make sure that my model ever ever sees this my model ever sees this right I should not allow my model to see this if my model sees this then there's a issue with respect to something called as data leakage okay so this may be a issue out there now the next thing that we are uh coming uh with respect to the next thing is that and what where does validation come into existence then so from this training data what we can do is that I can basically create another split one is called as training and one is called as validation now why this specific validation split is actually done this validation split is actually done so that we can hypertune our model this is basically for this is basically for hyperparameter tuning hyper parameter tuning okay that basically means we are specifically over here tuning the model okay let's say with the help of training data we are getting some accuracy but there is a task of hyper parameter tuning so what we do we use a concept of something called as cross validation cross validation so what does actually we do in Cross validation there's an example we use specifically we can use grid sear CV randomized SAR CV right randomize search CV and what we do we basically split our data that is our training data we split into train and validation suppose I say that I'm going to do cross validation my value is five that basically means I'm going to perform five different experiments okay in the first experiment suppose if my total training data set is th000 so if I'm performing cross validation is equal to 5 I'm going to divide this ,000 data set into five by five okay so this basically shows that my validation data size should be 200 in all the five experiments so in the first experiment the First Data this will be my validation data and the size will be 200 right remaining this will be 800 so this will be my training data right similarly if I go and probably construct my next experiment or cross validation the next 200 will be my uh validation data and remaining will be my training data then similarly I'll have next 200 like this I'll go and do all my 500 d right so this is one of the recent interview that was basically asked now coming to the second interview question second interview question was simple why why people use random Forest mostly instead of decision tree okay so this this is the question okay CU you know that in random Forest you have multiple decision trees but why do we specifically do this okay why do we use random Forest instead of decision tree or XG boost instead of decision tree so this you can basically answer I will just check out the comments but yes this is something related to bias and variance okay to provide to Pro avoid overfitting you know so when we say overfitting what what what is the type of bias and variance we have with respect to overfitting that basically training accuracy is very good test accuracy is very bad right so what is bias and variance in that specific case can I say low bias and high variance so decision tree usually has low bias and high variance right so in order to reduce this High variance to low variance and and specifically to keep this low bias as low bias we specifically use random Forest right so this is what we specifically use right so this can also be this was also one of the interview question that was asked to one of our subscriber or person who was studying in I neuron and he answered it well right so good should I follow this strategy prepare some interview questions yeah from tomorrow we'll also be having quiz today I did not get time to prepare the quiz questions but I hope everybody has got this right and yes random Forest is a bagging technique perfect okay so shall I start the today's session now yeah okay first now let's go ahead and discuss about something called as recurrent neural network we'll go slow by slow we'll try to understand what exactly is recurrent neural network and uh uh you know what all things we can actually do you know so all those things will be there in this now in recurrent neural network there are some important things right okay let's go ahead and discuss about the recurrent neural network now till now the things that we have seen to convert text to vectors okay when we are using text to vectors or when we are converting this text to vectors right what is the most efficient strategy we have found out till now tell me what is what is the most efficient way that we can basically find out or how we can actually do by converting text into vectors if I really want to go with text to vector vectors which is the most efficient way that we found out till now from all our previous session yes obviously many people are saying it right it is word to and then what we do we basically use average word to and this is nothing but this is a embedding layer right embedding layer this is something called as word embedding okay so this we have actually found out okay but let's talk about some amazing applications suppose I have have a specific chatbot now in case of a chatbot just consider an application with respect to chat in chatbot you ask a question and specifically you get a answer right it is just like a q& a so specific question whenever you are asking you get a specific answer okay so in this chatbot each and everything are very important the question right suppose if I'm asking a chat B Hey how for you what is the weather outside you know the chatbot should understand the proper context of all the question and probably answer it right so this is one application let's say over here what is the most important thing the sequence of words right are very important we have to make sure that this sequence of word is very very important right okay let's go to the next application have you have you seen uh language translation I hope everybody knows Google Translate right so in Google Translate you have a specific word from one language let's say from Hindi you want to convert into English right so here also sequence of the word is super important and you have to make sure that grammatically all this all this you know conversion should happen properly so that it can be used efficiently throughout the word right so language translation is also very important thing and probably if you go and see in Google Translation uh there how accurately you probably get all the language translated okay now if I take one more example okay over here uh let's say language translation is there chatbot is there you also have sentiment analysis let's say you have something called as text generation now right now if you open your Gmail and probably start writing a sentence right does it give you suggestion of the upcoming sentence suggestion it gives you the suggestion for the entire sentence grammatically right so this suggestion to completion of the St sentence completion of sentence so grammatically it gives you very well right so grammatically it makes sure that it provide you all the suggestion right so I think you have also seen this probably if you open Gmail and you start writing something automatically all the suggestion will come similarly in LinkedIn it also gives you Auto suggestion okay there's something called as Auto suggestion okay if you have a email ID suppose let's say the email says that or suppose if you have seen chatting in link right over there you probably write hey are you free you know so suddenly you get a suggestion okay create a video meeting okay something like that automatically multiple suggestions will be there right so all these kind of models the most important thing is sequences of words grammatically it needs to be right you know um entity models uh you also have entity label models right these all are simple very important here all these application are super important in terms of creating a real world application which does most of the task that actually people require very important task okay so for doing all these things we cannot be dependent on machine learning we cannot be dependent on machine learning so we have to be depend depent on deep learning techniques so deep learning techniques like what so deep learning techniques deep learning techniques like what like I can take RNN I can take lstm RNN you know because we will be training our vectors in this by using this neural networks right because machine learning will not be able to give us very good accuracy let's say lmrn and you have Transformers you have BD right efficient models and you know you know at one point of time you know Google search engine Let It Be or Gmail have used this kind of models and probably right now it may be using Transformers or it may be using BT you know because this is the most beautiful part you know so what we are going to do we going to learn slowly each and every architecture we are going to learn it with practical application and we are going to do it okay now people may be thinking Kish what is word to we then word to we is a technique in deep learning which we can train a model which we can train a model or we can use a pre-trained model which actually converts word into vectors okay and why this is much more efficient because semantic meaning is actually captured right the vectors that is basically created semantic meaning is actually captured right so I hope till here you have some amazing knowledge I hope you have understood till here yeah everyone and again whatever I'm teaching you this will be super important even in your interviews so can I get a quick yes if you're able to understand and uh if you're able to understand you know please do hit like that would be amazing for me put some symbols in the chat that will actually give me some amount of motivation right hugging face is also kind of Library which you can internally you can use Transformers to train a specific model and many more things okay okay now let's go ahead at least make 100 likes so that uh we continue now first first thing that we are actually going to discuss about is something called as recurrent neural network now why recurrent neural network is amazing okay a basic diagrams of the recurrent neural network that we can probably see let's say this is my neuron okay this is specifically output this is specifically input I have my input I have my output okay and this neuron may be a single neuron or it can be multiple neurons it can be even 100 neurons okay so just consider this one layer okay and whenever we get one kind of output this output is also sent back to the neuron Network okay this is the basic architecture of neural network uh recurrent neural network a basic architecture of recurrent neural network okay so we'll try to see to it okay now if I really want to expand this I can give this notation also or I can give this notation also see this notation also I can basically give Suppose there is a layer okay I have lot of neurons let's say 100 neurons or any number of neurons this takes one specific input this gives one specific output and this output can again be sent back to the neural network okay so this is another architecture that you can specifically use and there are multiple ways like suppose if I U just show you and probably if we also use some NLP applications like this right I will just say you okay RNN okay let's say I'm just going to search for RNN over here and let's go to the images okay see everybody can you see see this let's take this specific example we have an input we get a specific output and with respect to this output it is again given back to the neuron net very simple everyone clear can I get a quick yes see here also just focus on this I will try to draw this later on so I have a NE recurrent neural network I give an input I get an output and this output is again sent back to the neural network okay everybody clear Yes again one more example I have an input I have an output and again this output is also given back to the same network okay and anything that you probably see over here again I have an input I have an output and again it is given back to the same everybody clear yeah perfect so this is what it is okay now let's go ahead and let's try to expand this okay we will try to expand this network okay and uh I will try to expand it by considering a very simple application which is called as sentiment analysis okay sentiment analysis okay or or forget about this right now forget about this so we will try to see to it okay so I I have a network which takes one input which gives one output and then again this output is given back to it now if I try to expand this okay if I try to expand this okay so let's let's expand this okay so how this will get expanded so I will be having a neuron like this this will be my input sorry this will be my output this will be my input then what will happen since it is given back to its own network so here will be one output let's give this back to the same neuron like this which will be having one input and one output again okay then again this will be given back to the same and this will also be having one input and one input and like this it will be going to the next neuron which will be having one input and one input okay everybody clear simple okay now as we go what is this what is this you know the loop that you're doing every output is given to the next next every output is basically given to the same neural network right now can I say that this will work with respect to time stamp at T is equal to 1 this output is going over here then at T is equal to 2 this is basically getting calculated at T is equal to 3 this is getting at T is equal to n this is getting calculated yes or no I hope I hope everybody's clear with this simple neural network diagram yeah yeah everyone yes everyone so this is like T is equal to n right so over here what we are doing we are just whatever output it is generating we are giving it to the next time stamp of the same neural network okay same neural network right and this can be one neuron and this can be 100 neurons it is up to us okay everybody clear with this can I get a quick yes if you able to understand till here right very simple right now this is the entire process okay after this what will happen if probably we have this many time stamp now suppose I say let's focus on solving one problem statement which is called as sentiment analysis what is sentiment analysis either let's say I have a sentence okay the food is good right the food is good now if I say food is good let's say with respect to this my output sentiment is positive okay okay so my output sentiment is positive so here you can see yes definitely it is positive this is wow amazing okay now how do I send this information how do I send this information to our recurrent neural network very simple we'll try to see okay so this word that you see I will write it as X12 let's say sorry this is my first sentence let's say I'm representing this by X11 this is my X12 word this is my x13 word and this is my x14 word okay so here you can see this sentence is basically happening having four words okay now considering this neural network at T is equal to 1 which word I will actually provide because at a time I can only provide one input and I can get one output right so in T is equal to I will take up this first word and I will give it over here X11 okay then something will happen over here what will happen weights will get initialized I hope everybody knows a Ann so in Ann what will be there there will be an input layer and there is an hidden layer right this will get connected to this what is going to happen over here here weights are getting initialized right here here all the weights are getting initialized so similarly this X11 when we are providing we will definitely convert first this X11 by using word to true or not okay I hope everybody is able to understand first of all we will take this X11 we'll convert this into let's say we are using word to we'll convert this into some vectors of Dimension let's say this Dimension is D Dimension basically means how many features let's say 300 features are there okay so we are going to get this dimensions and this Dimension is going to get passed from here to this neuron Network right so here we are going to initialize some weights fine so when this is done some initialization will happen I'll get some output then what will happen this output will be sent to the next layer because at time T is equal to 2 I am going to take this X12 word so here I'm going to get my X12 word everybody clear so here I'm going to get my X12 word then again the same weights will get come over here right because weights will not get updated right now this is just a forward propagation similarly at T is equal to 3 I will get x13 so again weights will come over here x14 again weights will come over here everybody clear now yes yes yes yeah internally bias will get added bias will get added everywhere bias bias bias bias bias okay everybody clear how the weights is getting initialized you know that okay weights usually a lot of initialization techniques are there okay perfect everyone till here and like this now what will happen back propagation will happen forward propagation is here backward propagation is here that I'll write in terms of equation so this is the basic funa how a recurrent neural network actually works okay now let's discuss about the types of RNN types of RNN and I'm going to probably draw this in front of you okay suppose first of all there are multiple types one is one to one RNN okay second one is one two Sor one 2 one RNN one 12 1 RNN the second one is basically called as one to many RN and we'll understand with respect to this use case okay is it the exact output passing to the time stamp or some hidden State pass to the I will again discuss about it just say that this output is again getting passed over here okay I will talk about it I'll come back again and I'll show you the entire equation but before that I really want to teach you what is types of RNN okay then the third one is basically called as many to one RNN many to one RNN and finally I have something called as many to many RNN so these are the various types of RNN okay glove model will come Sur fros just give me some time okay okay let's see this suppose this is my neural network right I have one input I have one output okay and let's say over here the focus is that if I try to expand it if I try to expand it and obviously in RNN I have this so I will start this so here you have an input instead of retrieving the output here we will just send the output to the next one from here again input will be taken or no input will be taken let's say again the output is sent to the next one right again the next output is sent to the next one and finally I retrieve the output over here okay I retrieve the output over here everybody clear everybody clear so in this particular case do you see I am giving only one input and I'm getting only one output yes or no yes or no yes yes everyone I hope everybody is able to understand here what I'm actually talking about here what I'm actually specifically doing I'm giving one input and I'm getting one output yes or no yes in in the architecture here also I'll be getting an output but I'm not retrieving this I'm just removing this output I don't want it okay so in this particular case we basically say this as one to one recurrent neural network okay one input and finally one output okay now let's go ahead and understand the second one what is one to many now in one to many there will be obviously one input and what is the example for this this example can be anything right you can also use image classification using this you can do image classification right using this one image you'll be giving over here and one output what is the Class Type you may get over here you not CNN with the help of RNN also we can do image classification okay I'll show you one application but again right now not that important but just understand that uh if you also probably try to see it how uh this thing will happen I'll just tell you probably in some time okay so one to one uh let's focus on this one to one uh over here uh image classification can be a very good example okay now let's go to the second time one too many okay now one to many how does it look like okay everyone just see over here Focus over this is super super important uh these all things you should know then only you'll be able to understand well as we go ahead okay now one to one basically one to many so second type what we are going to discuss okay just give me a second okay just a second guys one to many okay so here is my neuron so in one to many again what will happen so this will be my representation but if I expand this the first thing is that I will be having one neuron like this this will be one too many okay and then this will go to the next one so I can take out this specific output also I can take out this specific output also I can take out this specific output also and like this I can take out this specific output also everybody clear everybody clear with this yes so here I have just one input and I have many outputs I have many outputs everybody clear I have a single input and I have many outputs okay so each and every layer output can also be taken with respect to time stamp like this will be t equal to 1 tal to 2 t equal to 3 T is equal to four everybody clear with the second type right one to many yes yes how many iteration does it take to get the desired output uh that depends on the loss function we'll discuss about this okay but I hope everybody has understood what is one to many right now can anybody tell me about some of the examples with respect to one to many anything that that you have in your mind very simple simple examples one to many right one to many one to many very simple example one to many anything that you have yes any examples music generation okay music generation yes music generation can can be a very good example so here I have specifically called as music generation in music generation what we do we give one input and then later on the further music can be actually calculated right so I can also say text generation right text generation is also one kind of example I give one text over there automatically all the text Will basically get created right any more example one to many anyone one to many yeah Google search suggestions so okay yeah perfect Google search suggestion is also a very good example because once you write an input multiple suggestions can be given to you right so this all can be amazing uh you know examples movie recommendation movie recommendation is also a very good example because based on that you will be able to get it right so see so many different different use cases have been used with respect to this kind of architecture okay now let's go to the third one third one is basically many to one now can maybe tell me what is the example with respect to many to one in many to one what will happen so I will have like this I will be having like this I will be having like this many to one what may be the example and this will be my one output and here I will specifically be getting continuous inputs okay what this can be any simple sentiment analysis right there there we give multiple words and finally my output is yes or no sentiment analysis right sentiment analysis uh can I say that okay uh from here I can also predict probably the next day sale predict next day sale this can also be an example by taking the previous data predict next sale next sale day right next day sale so this is also there as an example uh you can again see a lot of things with respect to this here we are providing multiple inputs and here I'm getting one output okay so super important super easy so this is with respect to many to one and now coming to the many to many can anybody tell me many to many which is the best example many to many many to many is a simple way where we specifically get one input get one output and then I go over here and I probably get one input one output right like this many to many will definitely be there right so I can probably Define like this right so in this particular case the best answer will be language translation right language translation okay uh second example question answering perfect question answering chat Bots right all these things will be the perfect examples for all these things everybody clear so how was the explanation till now yeah good yes clear if you liked it please make sure that you hit like and don't forget to subscribe Krishna Hindi Channel because I am also coming up with a lot of Hindi videos related to data science okay and this can be an interview question to you you know they may ask your use case they may say okay what is this kind of things tell me okay what is this kind of things tell me you know they may ask you anything so always be ready to answer those kind of questions they may ask you anything at any point of time you know they may say okay what is this example what is that example you know H okay perfect uh okay now let's go with respect to the forward propagation okay so now my topic will be something called as forward propagation in RN because whenever we learn about deep learning right there are two things one is forward propagation one is forward propagation and one is backward propagation backward propagation right so this two we are specifically going to discuss how things will basically happen Okay and uh see at the end of the day any complex problems that you see right now that are existing like that has been solved by Google you know that has been solved by Facebook you know specifically with respect to n LP or text Data where sequence is involved I'm not saying that RNN is only used for working with text Data RNN is used for working with time series data also okay so time series data also it is super important and it will be useful when you are specifically working with RNN okay and U you know this is it so let's go ahead and uh discuss about the forward propagation okay and we'll try to understand what exactly is forward propagation and all how does forward propagation actually happens in RNN quickly first of all we will uh draw a diagram and uh we'll try to understand anyhow if you don't understand something I'll always be there to help you out okay so quickly let me do one thing oh okay so let's go ahead and understand about the forward propagation and uh let's try to understand understand how does forward propagation basically happen Okay so for this I will just take a very simple example which is called as sentiment analysis now whenever I talk about sentimental analysis you should know it is nothing but many to one RNN okay many to one RNN you can Define your own RNN however you like but I am really much focused on many to one okay right now many to one you can also do with respect to many to many and whatever things you actually write okay now with respect to many to one uh let's consider this is my neural network okay I have a specific input I get an output and then I probably go to the next neural network uh this is my input output but since I'm saying many to one so I'm not going to consider this okay but anyhow the next whatever output is generated we are focusing on transferring it to the next neuron okay so here also one input and like this I will go and Define one more and this may be of any size you like Okay so let's say one more I'll Define so that maximum size is basically getting covered okay and after this um you know I specifically get an output over here okay now let's say this is my text as I said uh the text can be anything you know uh i' taken an example with respect to the food is very good the food is good how many four are there no five are there the food is very good right and with respect to this my output is positive right because this is a positive sentiment so in this particular instance this I will write it as X11 X12 x13 x14 X15 now when I say I'm passing X11 over here that basically I'm passing in the form of vectors okay always remember this you may be thinking how you know how this thing will actually happen now right now I'm just for focusing on forward propagation okay so X11 is going over here then what we do we initialize weights over here can I say here we are what kind of operation we'll specifically apply you know between this X1 and w11 one one specific operation we will probably apply right in forward propagation we are just going to multiply the inputs and the weights right so over here suppose if I'm getting this o1 this o1 and this output will be almost same right so the first operation of o1 is nothing but this neural network can I say this is a function because one multiplication will happen multiplication between X11 and W right so can I write X11 multiplied W right so this thing and I'll be getting o1 right very simple very simple I've not done anything I've just done this uh matrix multiplication of X11 with W X11 is in the form of vectors okay and this W that many number of w based on the neuron how many neurons are there we are going to just multiply with it then let's go over here now when I here I'm just going to pass X12 and again W will be used over here but since o1 is there this o1 this X1 and W1 and this neuron is also dependent on o1 right because this information is again getting passed over here so here I'm going to initialize another weight that is w-h let's say this is another weight right and I have to make sure that when I am multiplying this I also needs to get added to this because I'm also dependent this neuron this neural network is also dependent on the previous input so here what I'm going to do I'm going to create a function first multiplication will happen with X12 * W and then an addition will happen with o1 * W1 is it clear everybody yes I hope everybody is able to understand or this can be like a dot dot operation yes dot operation mment F multiplication okay so I hope everybody's clear with respect to this can I get a quick yes how it will identify the end of sentence in prop forward propagation so when I'll do practical application there will be something called as padding so I'll show you that how to do it don't worry about it right now I'll do a specific padding you know some size specific padding and then we'll try to understand then again over here I will get O2 now O2 will again get initialized with some weights and here I'm going to pass x13 this will be we then O3 then again weights then x14 uh W then o4 and this is w- w- and finally I will be having X15 and here I'm actually going to get it okay don't worry after this we specifically add a bias everywhere okay bias not that important right now but let's focus on this forward propagation right now but anyhow you can add bias whever you want okay so I'm just going to rub this so let's focus on this operation which is super now O3 will basically say what O3 is dependent on two things this two and this two so I will write a function of a function of uh you can basically see x13 * W plus O2 O2 multiplied by w- right so this will specifically be the operation with respect to O3 now like this all the operation will continue and it'll go till the end stage right till this specific stage okay till the end and you can continue writing this specific equation like this so finally in the output right we apply since this is many to one in many to one which kind of activation function we can apply with respect to the output many to one which kind of activation since if this output is a multiclass classification problem we specifically apply sigmoid right this I have already explained in my deep learning live sessions right when so not not multic class classification if it is a multiclass classification we basically apply soft Max right if it is a binary class classification we apply sigmoid right so for this for multiclass we apply this for binary we apply sigmoid right so either of this we specifically apply this two operation either this or this and finally I get what y hat right I finally get y hat after this this output is nothing but y hat okay so this is with respect to the forward propagation everybody clear yeah yeah everyone yes yeah I hope everybody's clear with this super important forward propagation everybody has understood and we have focused on how forward propagation is going to happen right now in the backward propagation what we focus on once we get y hat I'm going but I will also be having my original y value so I will try to calculate a loss function now a loss function let's say I'm going to use a simple loss function where I'm subtracting Y and Y hat okay and there are different type of loss function which I've again explained in different different loss function over here and with respect to this I'm going to update all these weights right I'm just going to update all the specific weights this weights this weights and this is going to happen with respect to all the time stamps so this was tal to 1 tal 2 tal 3 tal 4 and T is equal to 5 right everybody clear can I get a quick yes how does back propagation happen uh I will try to show you that in the next class but I really wanted to cover the forward propagation and already we had time uh because it is a 1 hour session uh and uh till here I hope everybody got an idea can I get a quick yes if you are got an idea till here so overall what we are going to do in the next class also after understanding backward propagation we're going to solve a practical problem I really want to cover each and everything you know each and everything with respect to the RNN also so that everybody understands from basic from scratch that will actually help you to gain your confidence right so overall I hope you liked it I'm just going to make sure that convert this into PDF okay and uh this PDF will be shared with all of you please make sure that you join the community link that is given in description of this particular video so this is NLP day 6 okay and uh I have I have created I hope everybody's liking my handwriting and you're able to understand everything that I'm drawing and teaching that is the amazing thing when I teach I always try to write all these things and probably explain you right so um yeah in the upcoming classes we'll be seeing lot of uh practical sessions also I really want to cover each and every bit so that you understand things right so please make sure that you subscribe Krishna Hindi Channel I hope how many of you have subscribed Krishna Hindi channel can you give me a quick yes if you have subscribed yes or no if you have not please do it because I'm also coming with a lot of Hindi videos right so I'm also coming up with a lot of Hindi videos right so please make sure that you do that uh because again I require your support to do anything in life uh so that I will be able to provide and anything if you really want to support my channel join the membership guys it'll be quite important for me so that I'll be able to you know do all this kind of live sessions for everyone provide you more information this is a request try to support by joining memberships try to support by giving some super thanks anything that would be amazing right so um yeah this was it from my side uh I hope you like this session please keep on supporting keep on uh sharing your knowledge never give up you if you find even some difficult things also make sure that you know try to not quit and try to learn for it uh this is super important from tomorrow we'll also be having quizzes uh today I did not get time because Saturday Sunday you know there was Jaton more than you know 80 person 80 people you know like around 10 to 15 got hired in uron and there were some people who got hired in migma and there's still interview processes going on in the future we whatever courses that we come up with uh will be super important okay one quick announcement that we have done guys uh this is super super important for everyone I really want to make this announcement quickly so that uh you don't miss this opportunity now any courses that comes up in uron you will be able to access access it through Tech neuron okay this is amazing let me just announce it quickly so here you can see that any courses now any courses that are going to come up see all these courses that are going to come up right will be available in Tech neuron okay it will be available in Tech neuron that is one neuron uh so here any live courses so all the live courses you'll be able to attend it so suppose if you log in over here and if you take it you will be probably able to to attend all the live courses the subscription plan is 2 years okay so you can go ahead and take it see just by paying somewhere around 10,000 rupees this is including GST if you go to one neuron here you'll be able to see so many things see this so here all these live sessions like system design that are going to happen in Saturday and Sunday digital marketing YouTube Mastery full stack data analytics in the future you will be having uh uh Enterprise Java job ready boot camp in C++ DSA and iot everything will be available to you or every every available courses that are going to come up live in I neuron that are also being available in Tech neuron so if you have already not used it uh please go ahead if you want additional code use Chris 10 you'll get 10% discount okay see I know you may be saying about manga this is very costly guys just understand because we for the next 2 years whatever courses that is going to come up all will be available for uh in your dashboard and you'll be able to uh get all the live sessions from the next two years that are going to come and every month we at least launch two to three courses also so please make sure that you go ahead take it up you know without wasting any time and all the upcoming courses anything right now full stack data analytics I am taking fhds batch I am actually taking so all this will be available to you here itself you'll be able to attend the live class directly from the zoom all you have to go and from this you'll also be able to get your own dashboard so this is your own separate dashboard okay own separate dashboard with all the pre-recorded videos and the live recordings will be available to you okay so yes uh I hope everybody like it um for the people who have bought it earlier I think that is a bumper offer for them in Tech neuron but again if you are looking for any discount you can use Krish 10 okay chrish 10 as code for 10 % off okay so yes uh try to help us try to uh you know uh you know this is not that much money for 2 years any number of live courses unlimited live courses right is super important and super easy for you all I guess and hardly right two times three times dinner party for with your family only that much it is so yes this was it from my side I hope you all support us with some amazing initiative that are coming up with and uh uh soon we are also coming up with the job portal it it is still in the testing phase we are testing it properly and yes once we do that it'll be available to you so thank you guys have a great day please hit like before we leave and I'll see you all in tomorrow's session bye-bye