# Chapter 3: Linear Regression Algorithm

## ğŸ¯ Learning Objectives
- Understand the mathematical foundation of linear regression
- Learn hypothesis function and cost function
- Master gradient descent optimization
- Understand R-squared and adjusted R-squared metrics

## ğŸ“š Key Concepts

### 3.1 What is Linear Regression?

**Definition**: Finding the best fit line through data points to predict continuous values

**Core Idea**: Y is a linear function of X

```mermaid
graph TD
    A[Training Data<br/>Age, Weight] --> B[Find Best Fit Line]
    B --> C[Prediction Model]
    C --> D[New Age â†’ Predicted Weight]

    E[Data Points<br/>24â†’62, 25â†’63, 21â†’72] --> B
```

### 3.2 Hypothesis Function

The equation of the best fit line can be written in multiple notations:

- **Traditional**: `y = mx + c`
- **Statistical**: `y = Î²â‚€ + Î²â‚x`
- **Machine Learning**: `hâ‚€(x) = Î¸â‚€ + Î¸â‚x`

**Parameters**:
- **Î¸â‚€ (Intercept)**: Value when X = 0 (where line meets Y-axis)
- **Î¸â‚ (Slope/Coefficient)**: Change in Y for 1 unit change in X

```mermaid
graph LR
    A[Input: Age] --> B[Hypothesis Function<br/>hÎ¸(x) = Î¸â‚€ + Î¸â‚x]
    B --> C[Output: Predicted Weight]

    D[Î¸â‚€: Intercept] --> B
    E[Î¸â‚: Slope] --> B
```

### 3.3 Cost Function (Mean Squared Error)

**Purpose**: Measure how well the model fits the data

**Formula**:
```
J(Î¸â‚€, Î¸â‚) = (1/2m) * Î£[hÎ¸(xáµ¢) - yáµ¢]Â²
```

**Components**:
- **m**: Number of data points
- **hÎ¸(xáµ¢)**: Predicted value
- **yáµ¢**: Actual value
- **(1/2m)**: Average + simplifies derivation

**Why Square?**
- Removes negative values
- Penalizes larger errors more
- Simplifies differentiation

### 3.4 Gradient Descent Optimization

**Goal**: Find the values of Î¸â‚€ and Î¸â‚ that minimize the cost function

```mermaid
graph TD
    A[Initialize Î¸â‚€, Î¸â‚] --> B[Calculate Cost]
    B --> C[Update Parameters]
    C --> D{Converged?}
    D -->|No| B
    D -->|Yes| E[Optimal Parameters]

    F[Learning Rate Î±] --> C
```

**Update Rules**:
```
Î¸â‚€ = Î¸â‚€ - Î± * (1/m) * Î£[hÎ¸(xáµ¢) - yáµ¢]
Î¸â‚ = Î¸â‚ - Î± * (1/m) * Î£[hÎ¸(xáµ¢) - yáµ¢] * xáµ¢
```

**Learning Rate (Î±)**:
- **Small Î±**: Takes tiny steps, slow convergence
- **Large Î±**: May overshoot, never converge
- **Typical values**: 0.01, 0.1, 0.001

**Gradient Descent Visualization**:

```mermaid
graph TD
    A[Cost Function<br/>J(Î¸â‚€, Î¸â‚)] --> B[Bowl Shape]
    B --> C[Global Minimum]

    D[High Cost] --> E[Medium Cost] --> F[Low Cost]

    G[Start Point] --> H[Move Downhill] --> I[Reach Minimum]
```

### 3.5 Mathematical Example

**Dataset**: (1,1), (2,2), (3,3)

**When Î¸â‚ = 1, Î¸â‚€ = 0**:
- hÎ¸(1) = 1, hÎ¸(2) = 2, hÎ¸(3) = 3
- J(Î¸â‚) = 0 (perfect fit)

**When Î¸â‚ = 0.5, Î¸â‚€ = 0**:
- hÎ¸(1) = 0.5, hÎ¸(2) = 1, hÎ¸(3) = 1.5
- J(Î¸â‚) â‰ˆ 0.58

**Cost Function Graph**:
- Î¸â‚ = 1 â†’ J = 0 (Global Minimum)
- Î¸â‚ = 0.5 â†’ J = 0.58
- Î¸â‚ = 0 â†’ J = 2.3

### 3.6 Model Evaluation Metrics

#### R-Squared (RÂ²)

**Formula**:
```
RÂ² = 1 - (SSR / SST)
```

Where:
- **SSR** = Î£[yáµ¢ - Å·áµ¢]Â² (Sum of Squared Residuals)
- **SST** = Î£[yáµ¢ - È³]Â² (Total Sum of Squares)

**Interpretation**:
- **RÂ² = 1**: Perfect fit
- **RÂ² = 0**: Model is as good as predicting mean
- **RÂ² < 0**: Model is worse than predicting mean

**Key Point**: SSR should be less than SST for good models

#### Adjusted R-Squared

**Problem with RÂ²**: Always increases with more features, even useless ones

**Formula**:
```
Adjusted RÂ² = 1 - [(1 - RÂ²) * (n - 1) / (n - p - 1)]
```

Where:
- **n**: Number of samples
- **p**: Number of features

**Advantage**: Penalyzes adding useless features

**Example**:
- 2 features: RÂ² = 90%, Adjusted RÂ² = 86%
- 3 features (with useless feature): RÂ² = 91%, Adjusted RÂ² = 82%

### 3.7 Complete Algorithm Flow

```mermaid
flowchart TD
    A[Data: Age, Weight] --> B[Initialize Î¸â‚€, Î¸â‚ randomly]
    B --> C[Calculate Predictions: hÎ¸(x)]
    C --> D[Calculate Cost: J(Î¸â‚€, Î¸â‚)]
    D --> E[Update Î¸â‚€, Î¸â‚ using Gradient Descent]
    E --> F{Cost Decreased?}
    F -->|Yes| C
    F -->|No| G[Convergence Reached]
    G --> H[Final Model Ready]
    H --> I[Predict New Values]
```

## â“ Interview Questions & Answers

### Q1: Why do we use squared error in the cost function instead of absolute error?
**Answer**:
- Squared error is differentiable everywhere (absolute error isn't)
- Squares penalize larger errors more heavily
- Makes the math cleaner (the 1/2 term cancels with derivative)
- Leads to convex optimization with guaranteed global minimum

### Q2: What happens if the learning rate is too high or too low?
**Answer**:
- **Too high**: Algorithm may overshoot the minimum and diverge
- **Too low**: Convergence is very slow, takes forever to reach minimum
- **Just right**: Steady convergence to optimal parameters

### Q3: Can gradient descent get stuck in local minima for linear regression?
**Answer**: No, linear regression cost function is always convex (bowl-shaped), so there's only one global minimum. Local minima are not a problem in linear regression, but they can be in deep learning.

### Q4: Why does RÂ² always increase when you add more features?
**Answer**: RÂ² measures the proportion of variance explained. Adding any feature (even random ones) will explain some additional variance, even if it's just noise. This is why we use Adjusted RÂ².

### Q5: What's the difference between Î¸â‚€ and Î¸â‚ in the hypothesis function?
**Answer**:
- **Î¸â‚€ (intercept)**: Baseline prediction when all features are zero
- **Î¸â‚ (coefficient/slope)**: Change in output for 1 unit change in input
- **Example**: In weight = Î¸â‚€ + Î¸â‚ Ã— age, Î¸â‚ shows how much weight increases per year

### Q6: How do you know when gradient descent has converged?
**Answer**: When the cost function stops decreasing significantly between iterations, or when the parameter updates become very small. Practical approach: stop when cost change < threshold (e.g., 0.001) or after maximum iterations.

### Q7: What's the purpose of the 1/2m term in the cost function?
**Answer**: The 1/m gives us the average error, and 1/2 is there to cancel out the 2 that comes from differentiation when we compute gradients. It's purely for mathematical convenience.

### Q8: Explain gradient descent with an analogy.
**Answer**: Imagine you're standing on a mountain in fog and want to reach the lowest point. You feel the slope beneath your feet and take a small step in the steepest downward direction. Repeat until you can't go lower. The "learning rate" is the size of your steps.

## ğŸ’¡ Key Takeaways

1. **Linear regression finds best fit line** through data points
2. **Cost function measures prediction error** using mean squared error
3. **Gradient descent updates parameters** to minimize cost
4. **Learning rate controls step size** in parameter updates
5. **RÂ² measures model fit**, Adjusted RÂ² accounts for number of features
6. **Convex cost function guarantees global minimum**

## ğŸš¨ Common Mistakes

**Mistake 1**: Using RÂ² to compare models with different numbers of features
- **Reality**: Use Adjusted RÂ² for fair comparison

**Mistake 2**: Setting learning rate too high
- **Reality**: Start with small values (0.01, 0.001) and adjust

**Mistake 3**: Forgetting to normalize features
- **Reality**: Feature scaling helps gradient descent converge faster

**Mistake 4**: Assuming linear regression works for all relationships
- **Reality**: Only works for linear relationships, check scatter plots first

## ğŸ“ Quick Revision Points

- **Hypothesis**: hÎ¸(x) = Î¸â‚€ + Î¸â‚x
- **Cost**: J(Î¸â‚€, Î¸â‚) = (1/2m) Î£[hÎ¸(xáµ¢) - yáµ¢]Â²
- **Gradient Descent**: Î¸â±¼ = Î¸â±¼ - Î± Ã— âˆ‚J/âˆ‚Î¸â±¼
- **RÂ²**: Measures variance explained by model
- **Adjusted RÂ²**: Penalizes useless features
- **Learning Rate**: Controls optimization step size
- **Convergence**: Stop when cost stops decreasing